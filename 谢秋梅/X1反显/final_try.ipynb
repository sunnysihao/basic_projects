{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "from datetime import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import time\n",
    "import logging\n",
    "\n",
    "\n",
    "# 64位ID的划分\n",
    "WORKER_ID_BITS = 5\n",
    "DATACENTER_ID_BITS = 5\n",
    "SEQUENCE_BITS = 12\n",
    "\n",
    "# 最大取值计算\n",
    "MAX_WORKER_ID = -1 ^ (-1 << WORKER_ID_BITS)  # 2**5-1 0b11111\n",
    "MAX_DATACENTER_ID = -1 ^ (-1 << DATACENTER_ID_BITS)\n",
    "\n",
    "# 移位偏移计算\n",
    "WOKER_ID_SHIFT = SEQUENCE_BITS\n",
    "DATACENTER_ID_SHIFT = SEQUENCE_BITS + WORKER_ID_BITS\n",
    "TIMESTAMP_LEFT_SHIFT = SEQUENCE_BITS + WORKER_ID_BITS + DATACENTER_ID_BITS\n",
    "\n",
    "# 序号循环掩码\n",
    "SEQUENCE_MASK = -1 ^ (-1 << SEQUENCE_BITS)\n",
    "\n",
    "# Twitter元年时间戳\n",
    "TWEPOCH = 1288834974657\n",
    "\n",
    "\n",
    "logger = logging.getLogger('flask.app')\n",
    "\n",
    "\n",
    "class IdWorker(object):\n",
    "    \"\"\"\n",
    "    用于生成IDs\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, datacenter_id, worker_id, sequence=0):\n",
    "        \"\"\"\n",
    "        初始化\n",
    "        :param datacenter_id: 数据中心（机器区域）ID\n",
    "        :param worker_id: 机器ID\n",
    "        :param sequence: 其实序号\n",
    "        \"\"\"\n",
    "        # sanity check\n",
    "        if worker_id > MAX_WORKER_ID or worker_id < 0:\n",
    "            raise ValueError('worker_id值越界')\n",
    "\n",
    "        if datacenter_id > MAX_DATACENTER_ID or datacenter_id < 0:\n",
    "            raise ValueError('datacenter_id值越界')\n",
    "\n",
    "        self.worker_id = worker_id\n",
    "        self.datacenter_id = datacenter_id\n",
    "        self.sequence = sequence\n",
    "\n",
    "        self.last_timestamp = -1  # 上次计算的时间戳\n",
    "\n",
    "    def _gen_timestamp(self):\n",
    "        \"\"\"\n",
    "        生成整数时间戳\n",
    "        :return:int timestamp\n",
    "        \"\"\"\n",
    "        return int(time.time() * 1000)\n",
    "\n",
    "    def get_id(self):\n",
    "        \"\"\"\n",
    "        获取新ID\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        timestamp = self._gen_timestamp()\n",
    "\n",
    "        # 时钟回拨\n",
    "        if timestamp < self.last_timestamp:\n",
    "            logging.error('clock is moving backwards. Rejecting requests until {}'.format(self.last_timestamp))\n",
    "            raise\n",
    "\n",
    "        if timestamp == self.last_timestamp:\n",
    "            self.sequence = (self.sequence + 1) & SEQUENCE_MASK\n",
    "            if self.sequence == 0:\n",
    "                timestamp = self._til_next_millis(self.last_timestamp)\n",
    "        else:\n",
    "            self.sequence = 0\n",
    "\n",
    "        self.last_timestamp = timestamp\n",
    "\n",
    "        new_id = ((timestamp - TWEPOCH) << TIMESTAMP_LEFT_SHIFT) | (self.datacenter_id << DATACENTER_ID_SHIFT) | \\\n",
    "                 (self.worker_id << WOKER_ID_SHIFT) | self.sequence\n",
    "        return new_id\n",
    "\n",
    "    def _til_next_millis(self, last_timestamp):\n",
    "        \"\"\"\n",
    "        等到下一毫秒\n",
    "        \"\"\"\n",
    "        timestamp = self._gen_timestamp()\n",
    "        while timestamp <= last_timestamp:\n",
    "            timestamp = self._gen_timestamp()\n",
    "        return timestamp\n",
    "\n",
    "\n",
    "class JsonEncoder(json.JSONEncoder):\n",
    "    \"\"\"Convert numpy classes to JSON serializable objects.\"\"\"\n",
    "\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, (np.integer, np.floating, np.bool_)):\n",
    "            return obj.item()\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        else:\n",
    "            return super(JsonEncoder, self).default(obj)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "class_engine = sqlalchemy.create_engine('mysql+pymysql://zhangsihao:x8FWKH0YgTqc7UPt@54.219.241.164:14000/basicai_annotation')\n",
    "result_engine = sqlalchemy.create_engine('mysql+pymysql://basicai:mP3L0S93@nlb.alidev.beisai.com:4000/basicai_dataset')\n",
    "target_engine = sqlalchemy.create_engine('mysql+pymysql://zhangsihao:x8FWKH0YgTqc7UPt@54.219.241.164:14000/basicai_dataset')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception during reset or similar\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\pymysql\\connections.py\", line 756, in _write_bytes\n",
      "    self._sock.sendall(data)\n",
      "ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sqlalchemy\\pool\\base.py\", line 682, in _finalize_fairy\n",
      "    fairy._reset(pool)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sqlalchemy\\pool\\base.py\", line 887, in _reset\n",
      "    pool._dialect.do_rollback(self)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sqlalchemy\\engine\\default.py\", line 667, in do_rollback\n",
      "    dbapi_connection.rollback()\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\pymysql\\connections.py\", line 479, in rollback\n",
      "    self._execute_command(COMMAND.COM_QUERY, \"ROLLBACK\")\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\pymysql\\connections.py\", line 814, in _execute_command\n",
      "    self._write_bytes(packet)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\pymysql\\connections.py\", line 759, in _write_bytes\n",
      "    raise err.OperationalError(\n",
      "pymysql.err.OperationalError: (2006, \"MySQL server has gone away (ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))\")\n"
     ]
    }
   ],
   "source": [
    "dataset_class_sql='''\n",
    "select * from dataset_class where team_id=90168\n",
    "'''\n",
    "df_class = pd.read_sql(dataset_class_sql,class_engine)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "data": {
      "text/plain": "[90379,\n 90383,\n 90384,\n 90387,\n 90400,\n 90404,\n 90451,\n 90453,\n 90468,\n 90925,\n 120418,\n 120423,\n 120424,\n 120444,\n 120448,\n 120455,\n 120457,\n 120471,\n 120505,\n 120506,\n 120760,\n 120927,\n 120928,\n 120929,\n 120930,\n 150864,\n 1080051,\n 1080052,\n 1080053,\n 1080054,\n 1080129,\n 1080130,\n 1080708,\n 1110140,\n 1110141,\n 1110142]"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(set(df_class['dataset_id'])))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "file = r\"D:\\倍赛\\data_ids.json\"\n",
    "j_data = {\n",
    "    \"ids\": sorted(list(set(df_class['dataset_id'])))[296:]\n",
    "}\n",
    "with open(file, 'w', encoding='utf-8') as idf:\n",
    "    json.dump(j_data, idf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "dataset_result_sql='''\n",
    "select * from data_annotation_result where team_id=90030\n",
    "'''\n",
    "df_result = pd.read_sql(dataset_result_sql,result_engine)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: [id, team_id, dataset_id, data_id, version, source_type, source_id, validity, classification_values, objects, created_at, created_by, updated_at, updated_by]\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>team_id</th>\n      <th>dataset_id</th>\n      <th>data_id</th>\n      <th>version</th>\n      <th>source_type</th>\n      <th>source_id</th>\n      <th>validity</th>\n      <th>classification_values</th>\n      <th>objects</th>\n      <th>created_at</th>\n      <th>created_by</th>\n      <th>updated_at</th>\n      <th>updated_by</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "class_name_id_mapping = {}\n",
    "name_attr_mapping = {}\n",
    "for x in df_class.iloc:\n",
    "    class_name = x['name']\n",
    "    class_id = x['id']\n",
    "    class_name_id_mapping[class_name] = str(class_id)\n",
    "    class_atts = json.loads(x['attributes'])\n",
    "    attr_id_mapping = {}\n",
    "    for att in class_atts:\n",
    "        name = att['name']\n",
    "        id = att['id']\n",
    "        attr_id_mapping[name] = id\n",
    "    name_attr_mapping[class_name] = attr_id_mapping"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "{'Car': '201385',\n 'Van': '201386',\n 'Truck': '201387',\n 'bus': '204514',\n 'car': '411783',\n 'person': '381867',\n 'motorcycle': '411784'}"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_name_id_mapping"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "{'Car': {'Occlusion': 'f359e99e-d98b-4306-8639-22a65ed2eab0',\n  'Confidence': '64b4b2ad-c83f-4f7f-98bc-8627c0bd2cbe'},\n 'Van': {'Occlusion': 'dcd302ef-2b88-492b-954f-88406067caa0',\n  'Confidence': '624289f6-e260-41c8-b052-581b885020b2'},\n 'Truck': {'Occlusion': '9c83bdc1-8014-490a-a4f0-65e798783529',\n  'Confidence': 'b1ef630c-295e-4024-b88e-bf5d02e76bba'},\n 'bus': {'a': '8feeac7b-18ad-44b7-91b9-c9e174069100'},\n 'car': {'occlusion': '801f3717-3553-4a6f-a342-13bc7fc389aa'},\n 'person': {},\n 'motorcycle': {'occlusion': 'c3a3b2fa-e6c8-44d8-bc19-087e2478a8e8'}}"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_attr_mapping"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "worker = IdWorker(1, 2, 0)\n",
    "dat = [{\n",
    "    \"id\": None,\n",
    "    \"team_id\": 120231,\n",
    "    \"serial_number\": worker.get_id(),\n",
    "    \"file_url\": None,\n",
    "    \"file_name\": None,\n",
    "    \"error_message\": None,\n",
    "    \"total_file_size\": None,\n",
    "    \"downloaded_file_size\": None,\n",
    "    \"total_data_num\": None,\n",
    "    \"parsed_data_num\": None,\n",
    "    \"status\": None,\n",
    "    \"created_at\": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    \"created_by\": None,\n",
    "    \"updated_at\": None,\n",
    "    \"updated_by\": None\n",
    "}]\n",
    "data = pd.DataFrame(dat)\n",
    "\n",
    "data.to_sql('upload_record', con=target_engine,index=False,if_exists='append')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset_result_source_write = {\n",
    "    \"id\": None,\n",
    "    \"team_id\": [120231],\n",
    "    \"dataset_id\": [990007],\n",
    "    \"result_name\": ['zsh_test_fusion'],\n",
    "    \"source_id\": [600003],\n",
    "    \"source_type\": ['EXTERNAL_GROUND_TRUTH'],\n",
    "    \"created_at\": [datetime.now().strftime('%Y-%m-%d %H:%M:%S')],\n",
    "    \"created_by\": [600002],\n",
    "    \"updated_at\": None,\n",
    "    \"updated_by\": None\n",
    "}\n",
    "data_result_source = pd.DataFrame(dataset_result_source_write)\n",
    "\n",
    "data_result_source.to_sql('dataset_result_source', con=engine,index=False,if_exists='append')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}