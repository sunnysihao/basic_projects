{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PointCloud' object has no attribute 'parse_binary_compressed_pc_data'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[1;32mIn [1]\u001B[0m, in \u001B[0;36m<cell line: 245>\u001B[1;34m()\u001B[0m\n\u001B[0;32m    243\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m points\n\u001B[0;32m    245\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m--> 246\u001B[0m     pc \u001B[38;5;241m=\u001B[39m \u001B[43mload_pc_data\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43mr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mD:\u001B[39;49m\u001B[38;5;124;43m\\\u001B[39;49m\u001B[38;5;124;43mDesktop\u001B[39;49m\u001B[38;5;124;43m\\\u001B[39;49m\u001B[38;5;124;43mBasicProject\u001B[39;49m\u001B[38;5;124;43m\\\u001B[39;49m\u001B[38;5;124;43m王满顺\u001B[39;49m\u001B[38;5;124;43m\\\u001B[39;49m\u001B[38;5;124;43m理想\u001B[39;49m\u001B[38;5;124;43m\\\u001B[39;49m\u001B[38;5;124;43m点云试标数据1019\u001B[39;49m\u001B[38;5;124;43m\\\u001B[39;49m\u001B[38;5;124;43m点云试标\u001B[39;49m\u001B[38;5;124;43m\\\u001B[39;49m\u001B[38;5;124;43mAT128_A4202203150920_940_1647307296293685\u001B[39;49m\u001B[38;5;124;43m\\\u001B[39;49m\u001B[38;5;124;43mpcd\u001B[39;49m\u001B[38;5;124;43m\\\u001B[39;49m\u001B[38;5;124;43mAT128_A4202203150920_940_1647307296293685.pcd\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[1;32mIn [1]\u001B[0m, in \u001B[0;36mload_pc_data\u001B[1;34m(pcd_file)\u001B[0m\n\u001B[0;32m    233\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload_pc_data\u001B[39m(pcd_file):\n\u001B[0;32m    234\u001B[0m     \u001B[38;5;66;03m# import argparse\u001B[39;00m\n\u001B[0;32m    235\u001B[0m     \u001B[38;5;66;03m# parser = argparse.ArgumentParser()\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    239\u001B[0m     \u001B[38;5;66;03m# from time import time\u001B[39;00m\n\u001B[0;32m    240\u001B[0m     \u001B[38;5;66;03m# start = time()\u001B[39;00m\n\u001B[1;32m--> 241\u001B[0m     pc \u001B[38;5;241m=\u001B[39m \u001B[43mPointCloud\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpcd_file\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    242\u001B[0m     points \u001B[38;5;241m=\u001B[39m pc\u001B[38;5;241m.\u001B[39mnumpy(dtype\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mfloat64)\n\u001B[0;32m    243\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m points\n",
      "Input \u001B[1;32mIn [1]\u001B[0m, in \u001B[0;36mPointCloud.__init__\u001B[1;34m(self, pcd_file)\u001B[0m\n\u001B[0;32m     28\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(pcd_file, (\u001B[38;5;28mstr\u001B[39m, Path)):\n\u001B[0;32m     29\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(pcd_file, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[1;32m---> 30\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_load_from_file\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     31\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     32\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_load_from_file(pcd_file)\n",
      "Input \u001B[1;32mIn [1]\u001B[0m, in \u001B[0;36mPointCloud._load_from_file\u001B[1;34m(self, f)\u001B[0m\n\u001B[0;32m    192\u001B[0m     pc \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_parse_points_from_buf(buf, dtype)\n\u001B[0;32m    193\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m code \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbinary_compressed\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m--> 194\u001B[0m     pc \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparse_binary_compressed_pc_data\u001B[49m(f, dtype, metadata)\n\u001B[0;32m    195\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    196\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124minvalid pcd DATA: \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcode\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'PointCloud' object has no attribute 'parse_binary_compressed_pc_data'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from numpy.lib.recfunctions import repack_fields\n",
    "import re\n",
    "import struct\n",
    "import lzf\n",
    "\n",
    "numpy_pcd_type_mappings = [\n",
    "    (np.dtype('float32'), ('F', 4)),\n",
    "    (np.dtype('float64'), ('F', 8)),\n",
    "    (np.dtype('uint8'), ('U', 1)),\n",
    "    (np.dtype('uint16'), ('U', 2)),\n",
    "    (np.dtype('uint32'), ('U', 4)),\n",
    "    (np.dtype('uint64'), ('U', 8)),\n",
    "    (np.dtype('int16'), ('I', 2)),\n",
    "    (np.dtype('int32'), ('I', 4)),\n",
    "    (np.dtype('int64'), ('I', 8))]\n",
    "numpy_type_to_pcd_type = dict(numpy_pcd_type_mappings)\n",
    "pcd_type_to_numpy_type = dict((q, p) for (p, q) in numpy_pcd_type_mappings)\n",
    "\n",
    "\n",
    "class PointCloud:\n",
    "    def __init__(self, pcd_file):\n",
    "        self.metadata = None\n",
    "        self.code = None\n",
    "\n",
    "        if pcd_file is not None:\n",
    "            if isinstance(pcd_file, (str, Path)):\n",
    "                with open(pcd_file, 'rb') as f:\n",
    "                    self.data = self._load_from_file(f)\n",
    "            else:\n",
    "                self.data = self._load_from_file(pcd_file)\n",
    "\n",
    "    @property\n",
    "    def fields(self):\n",
    "        return self.data.dtype.names\n",
    "\n",
    "    def valid_fields(self, fields=None):\n",
    "        if fields is None:\n",
    "            fields = self.data.dtype.names\n",
    "        else:\n",
    "            fields = [\n",
    "                f\n",
    "                for f in fields\n",
    "                if f in self.data.dtype.names\n",
    "            ]\n",
    "        return fields\n",
    "\n",
    "    def numpy(self, fields=None, dtype=np.float32):\n",
    "        fields = self.valid_fields(fields)\n",
    "        return np.stack([\n",
    "            self.data[name].astype(dtype)\n",
    "            for name in fields\n",
    "        ], axis=1)\n",
    "\n",
    "    def normalized_fields(self, extra_fields: list = None):\n",
    "        all_fields = set(self.fields)\n",
    "\n",
    "        fields = ['x', 'y', 'z']\n",
    "        for f in fields:\n",
    "            if f not in all_fields:\n",
    "                raise ValueError(f'can not find \"{f}\" field in pcd file')\n",
    "\n",
    "        if 'intensity' in all_fields:\n",
    "            fields.append('intensity')\n",
    "        elif 'i' in all_fields:\n",
    "            fields.append('i')\n",
    "\n",
    "        if extra_fields:\n",
    "            for f in extra_fields:\n",
    "                if f in all_fields:\n",
    "                    fields.append(f)\n",
    "        return fields\n",
    "\n",
    "    def normalized_numpy(self, extra_fields: list = None, dtype=np.float32):\n",
    "        fields = self.normalized_fields(extra_fields)\n",
    "        return self.numpy(fields, dtype)\n",
    "\n",
    "    def normalized_pc(self, extra_fields: list = None):\n",
    "        fields = self.normalized_fields(extra_fields)\n",
    "        return repack_fields(self.data[fields])\n",
    "\n",
    "    @staticmethod\n",
    "    def _build_dtype(metadata):\n",
    "        fieldnames = []\n",
    "        typenames = []\n",
    "\n",
    "        # process dulipcated names\n",
    "        fields = metadata['fields']\n",
    "        fields_dict = set()\n",
    "        for i in range(len(fields)):\n",
    "            name = fields[i]\n",
    "            if name in fields_dict:\n",
    "                while name in fields_dict:\n",
    "                    name += '1'\n",
    "                fields[i] = name\n",
    "            fields_dict.add(name)\n",
    "\n",
    "        for f, c, t, s in zip(fields,\n",
    "                            metadata['count'],\n",
    "                            metadata.get('type', 'F'),\n",
    "                            metadata['size']):\n",
    "            np_type = pcd_type_to_numpy_type[(t, s)]\n",
    "            if c == 1:\n",
    "                fieldnames.append(f)\n",
    "                typenames.append(np_type)\n",
    "            elif c == 0: # zero count\n",
    "                continue\n",
    "            elif c < 0: # negative count\n",
    "                left_count = -c\n",
    "                while left_count > 0:\n",
    "                    left_count -= typenames[-1].itemsize\n",
    "                    fieldnames.pop()\n",
    "                    typenames.pop()\n",
    "            else:\n",
    "                fieldnames.extend(['%s_%04d' % (f, i) for i in range(c)])\n",
    "                typenames.extend([np_type]*c)\n",
    "        dtype = np.dtype(list(zip(fieldnames, typenames)))\n",
    "        return dtype\n",
    "\n",
    "    def parse_header(self, lines):\n",
    "        \"\"\" Parse header of PCD files.\n",
    "        \"\"\"\n",
    "        metadata = {}\n",
    "        for ln in lines:\n",
    "            if ln.startswith('#') or len(ln) < 2:\n",
    "                continue\n",
    "            match = re.match('(\\w+)\\s+([\\w\\s\\.\\-]+)', ln)\n",
    "            if not match:\n",
    "                print(\"warning: can't understand line: %s\" % ln)\n",
    "                continue\n",
    "            key, value = match.group(1).lower(), match.group(2)\n",
    "            if key == 'version':\n",
    "                metadata[key] = value\n",
    "            elif key in ('fields', 'type'):\n",
    "                metadata[key] = value.split()\n",
    "            elif key in ('size', 'count'):\n",
    "                metadata[key] = list(map(int, value.split()))\n",
    "            elif key in ('width', 'height', 'points'):\n",
    "                metadata[key] = int(value)\n",
    "            elif key == 'viewpoint':\n",
    "                metadata[key] = map(float, value.split())\n",
    "            elif key == 'data':\n",
    "                metadata[key] = value.strip().lower()\n",
    "            # TODO apparently count is not required?\n",
    "        # add some reasonable defaults\n",
    "        if 'count' not in metadata:\n",
    "            metadata['count'] = [1]*len(metadata['fields'])\n",
    "        if 'viewpoint' not in metadata:\n",
    "            metadata['viewpoint'] = [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n",
    "        if 'version' not in metadata:\n",
    "            metadata['version'] = '.7'\n",
    "        return metadata\n",
    "\n",
    "    @staticmethod\n",
    "    def _parse_points_from_buf(buf, dtype):\n",
    "        return np.frombuffer(buf, dtype=dtype)\n",
    "\n",
    "    def parse_binary_compressed_pc_data(self, f, dtype, metadata):\n",
    "        \"\"\" Parse lzf-compressed data.\n",
    "        \"\"\"\n",
    "        fmt = 'II'\n",
    "        compressed_size, uncompressed_size = struct.unpack(fmt, f.read(struct.calcsize(fmt)))\n",
    "        compressed_data = f.read(compressed_size)\n",
    "\n",
    "        buf = lzf.decompress(compressed_data, uncompressed_size)\n",
    "        if len(buf) != uncompressed_size:\n",
    "            raise IOError('Error decompressing data')\n",
    "        # the data is stored field-by-field\n",
    "        pc_data = self._parse_points_from_buf(buf, dtype)\n",
    "        return pc_data\n",
    "\n",
    "    def _load_from_file(self, f):\n",
    "        header = []\n",
    "        for _ in range(11):\n",
    "            ln = f.readline().decode(\"ascii\").strip()\n",
    "            header.append(ln)\n",
    "            if ln.startswith('DATA'):\n",
    "                metadata = self.parse_header(header)\n",
    "                self.code = code = metadata['data']\n",
    "                dtype = self._build_dtype(metadata)\n",
    "                break\n",
    "        else:\n",
    "            raise ValueError(\"invalid file header\")\n",
    "\n",
    "        if code == 'ascii':\n",
    "            pc = np.genfromtxt(f, dtype=dtype, delimiter=' ') # np.loadtxt is too slow\n",
    "            # pc = np.fromfile(f, dtype=dtype, sep=' ') # error\n",
    "        elif code == 'binary':\n",
    "            rowstep = metadata['points']*dtype.itemsize\n",
    "            buf = f.read(rowstep)\n",
    "            pc = self._parse_points_from_buf(buf, dtype)\n",
    "        elif code == 'binary_compressed':\n",
    "            pc = self.parse_binary_compressed_pc_data(f, dtype, metadata)\n",
    "        else:\n",
    "            raise ValueError(f'invalid pcd DATA: \"{code}\"')\n",
    "\n",
    "        return pc\n",
    "\n",
    "    @staticmethod\n",
    "    def save_pcd(pc: np.ndarray, file):\n",
    "        \"\"\"\n",
    "        :param structured ndarray\n",
    "        :param file: str for file object\n",
    "        \"\"\"\n",
    "        fields = pc.dtype.names\n",
    "        if isinstance(file, str):\n",
    "            f = open(file, 'wb')\n",
    "\n",
    "        num_points = len(pc)\n",
    "        num_fields = len(fields)\n",
    "        dtypes = [pc.dtype[f] for f in fields]\n",
    "        headers = [\n",
    "            '# .PCD v0.7 - Point Cloud Data file format',\n",
    "            'VERSION 0.7',\n",
    "            f'FIELDS {\" \".join(fields)}',\n",
    "            f'SIZE {\" \".join([str(d.itemsize) for d in dtypes])}',\n",
    "            f'TYPE {\" \".join([d.kind.upper() for d in dtypes])}',\n",
    "            f'COUNT {\" \".join([\"1\"]*num_fields)}',\n",
    "            f'WIDTH {num_points}',\n",
    "            'HEIGHT 1',\n",
    "            'VIEWPOINT 0 0 0 1 0 0 0',\n",
    "            f'POINTS {num_points}',\n",
    "            'DATA binary'\n",
    "        ]\n",
    "        header = bytes('\\n'.join(headers) + '\\n', 'ascii')\n",
    "        f.write(header)\n",
    "        f.write(pc.tobytes())\n",
    "\n",
    "        if isinstance(file, str):\n",
    "            f.close()\n",
    "\n",
    "def load_pc_data(pcd_file):\n",
    "    # import argparse\n",
    "    # parser = argparse.ArgumentParser()\n",
    "    # parser.add_argument('pcd_file', type=str)\n",
    "    # args = parser.parse_args()\n",
    "\n",
    "    # from time import time\n",
    "    # start = time()\n",
    "    pc = PointCloud(pcd_file)\n",
    "    points = pc.numpy(dtype=np.float64)\n",
    "    return points\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    pc = load_pc_data(r\"D:\\Desktop\\BasicProject\\王满顺\\理想\\点云试标数据1019\\点云试标\\AT128_A4202203150920_940_1647307296293685\\pcd\\AT128_A4202203150920_940_1647307296293685.pcd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-2.17733154e+01, -5.41472473e+01, -5.42752482e-02,\n         2.34180515e-38],\n       [-2.13059063e+01, -5.37947960e+01,  1.26488984e+00,\n         2.34180515e-38],\n       [-3.28066483e+01, -5.79734459e+01,  3.93885779e+00,\n         2.34180515e-38],\n       [-3.21665878e+01, -5.77284355e+01,  4.34762716e+00,\n         2.34180515e-38],\n       [-1.54019947e+01, -4.23169594e+01,  7.32784176e+00,\n         2.34180515e-38],\n       [-3.26394653e+01, -5.78658752e+01,  5.19266033e+00,\n         2.34180515e-38],\n       [-3.30973244e+01, -5.72535210e+01,  3.52219057e+00,\n         2.34180515e-38],\n       [-3.26983948e+01, -5.79559059e+01,  3.49214625e+00,\n         2.34180515e-38],\n       [-3.28902626e+01, -5.61857185e+01,  3.76551771e+00,\n         2.34180515e-38],\n       [-3.31720886e+01, -5.72855225e+01,  3.72058582e+00,\n         2.34180515e-38],\n       [-3.26387253e+01, -5.79314156e+01,  3.69067359e+00,\n         2.34180515e-38],\n       [-3.46984406e+01, -5.64519424e+01, -2.53196564e-02,\n         2.34180515e-38],\n       [-2.92365360e+01, -5.25889244e+01, -2.24083260e-01,\n         2.34180515e-38],\n       [-1.95093250e+01, -4.54982834e+01, -1.88792214e-01,\n         2.34180515e-38],\n       [-1.08843575e+01, -3.91808472e+01, -9.25680250e-02,\n         2.34180515e-38],\n       [ 3.46177053e+00, -2.90506153e+01, -1.13470532e-01,\n         2.34180515e-38],\n       [ 4.39166546e+00, -3.98072662e+01, -1.82658374e-01,\n         2.34180515e-38],\n       [-3.28428574e+01, -5.71405220e+01,  3.10929704e+00,\n         2.34180515e-38],\n       [-3.08581429e+01, -5.73127403e+01,  2.98227024e+00,\n         2.34180515e-38],\n       [-3.27391052e+01, -5.70833435e+01,  3.31407857e+00,\n         2.34180515e-38]])"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc[:20]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def RGB_to_Hex(rgb):\n",
    "    RGB = rgb.split(',')            # 将RGB格式划分开来\n",
    "    color = '#'\n",
    "    for i in RGB:\n",
    "        num = int(i)\n",
    "        # 将R、G、B分别转化为16进制拼接转换并大写  hex() 函数用于将10进制整数转换成16进制，以字符串形式表示\n",
    "        color += str(hex(num))[-2:].replace('x', '0').upper()\n",
    "    # print(color)\n",
    "    return color\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "with open(r\"D:\\Desktop\\BasicProject\\decimal_1652432982.123255968_0.000_0.013.pcd\", 'w', encoding='ascii') as pcd_file:\n",
    "    point_num = pc.shape[0]\n",
    "    heads = [\n",
    "        '# .PCD v0.7 - Point Cloud Data file format',\n",
    "        'VERSION 0.7',\n",
    "        'FIELDS x y z rgb',\n",
    "        'SIZE 4 4 4 4',\n",
    "        'TYPE F F F F',\n",
    "        'COUNT 1 1 1 1',\n",
    "        f'WIDTH {point_num}',\n",
    "        'HEIGHT 1',\n",
    "        'VIEWPOINT 0 0 0 1 0 0 0',\n",
    "        f'POINTS {point_num}',\n",
    "        'DATA ascii'\n",
    "    ]\n",
    "\n",
    "    pcd_file.write('\\n'.join(heads))\n",
    "    for i in range(point_num):\n",
    "        string_point = '\\n' + str(pc[i, 0]) + ' ' + str(pc[i, 1]) + ' ' + str(pc[i, 2]) + ' ' + str(\n",
    "            hex(int(pc[i, 3])))\n",
    "        pcd_file.write(string_point)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}